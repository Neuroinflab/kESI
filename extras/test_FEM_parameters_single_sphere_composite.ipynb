{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import FEM.fem_sphere_point_new as fspn\n",
    "import FEM.fem_common as fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 89e-3\n",
    "GEOMETRY = 'single_sphere_composite'\n",
    "PROPERTIES = 'FEM/model_properties/single_sphere.ini'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MESHES = ['coarse',\n",
    "          'normal',\n",
    "          'fine',\n",
    "          'finer',\n",
    "          'finest',\n",
    "          'superfine',\n",
    "          ]\n",
    "\n",
    "DEGREES = [1, 2, 3]\n",
    "\n",
    "CONFIGS = list(itertools.product(MESHES, DEGREES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MESH_DIR = 'FEM/meshes/meshes/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULT_DIR = os.path.join('test_FEM_parameters',\n",
    "                          GEOMETRY)\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "POINTS_FILE = os.path.join(RESULT_DIR,\n",
    "                           'point.csv')\n",
    "\n",
    "if os.path.exists(POINTS_FILE):\n",
    "    print(POINTS_FILE, 'found')\n",
    "    POINTS = pd.read_csv(POINTS_FILE,\n",
    "                         index_col=0)\n",
    "\n",
    "else:\n",
    "    random.seed(42)\n",
    "    POINTS = np.full((N, 3), np.nan)\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    while i < N:\n",
    "        x = random.uniform(-R, R)\n",
    "        y = random.uniform(-R, R)\n",
    "        z = random.uniform(-R, R)\n",
    "        if x ** 2 + y ** 2 + z ** 2 < R ** 2:\n",
    "            POINTS[i, :] = x, y, z\n",
    "            i += 1\n",
    "            \n",
    "    POINTS = pd.DataFrame(POINTS, columns=['X', 'Y', 'Z'])\n",
    "    POINTS.to_csv(POINTS_FILE,\n",
    "                  index_label='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup_time = fc.fc.Stopwatch()\n",
    "total_solving_time = fc.fc.Stopwatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mesh, degree in CONFIGS:\n",
    "    print(mesh, degree)\n",
    "    result_file = os.path.join(RESULT_DIR,\n",
    "                               f'{mesh}_{degree}.csv')\n",
    "    \n",
    "    if os.path.exists(result_file):\n",
    "        print(' ', result_file, 'found')\n",
    "        continue\n",
    "    \n",
    "    DF = []\n",
    "    with setup_time:\n",
    "        function_manager = fc.FunctionManager(os.path.join(MESH_DIR,\n",
    "                                                           GEOMETRY,\n",
    "                                                           f'{mesh}.xdmf'),\n",
    "                                              degree,\n",
    "                                              'CG')\n",
    "        fem = fspn.SphereOnGroundedPlatePointSourcePotentialFEM(function_manager,\n",
    "                                                                PROPERTIES)\n",
    "\n",
    "    for src, SRC in POINTS.iterrows():\n",
    "        print(mesh, degree, src)\n",
    "        with total_solving_time:\n",
    "            potential_corr = fem.correction_potential(SRC.X, SRC.Y, SRC.Z)\n",
    "            \n",
    "        for dst, DST in POINTS.iterrows():\n",
    "            DF.append({\n",
    "                'SRC': src,\n",
    "                'DST': dst,\n",
    "                'CORR': potential_corr(DST.X, DST.Y, DST.Z),\n",
    "                'SOLVING_TIME': float(total_solving_time),\n",
    "                'SETUP_TIME': float(setup_time)\n",
    "            })\n",
    "            \n",
    "    DF = pd.DataFrame(DF)\n",
    "    DF.to_csv(result_file, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from local import cbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "from kesi import common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read(PROPERTIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BRAIN_CONDUCTIVITY = config.getfloat('brain', 'conductivity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading correction matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "corrections = []\n",
    "\n",
    "for mesh, degree in CONFIGS:\n",
    "    print(mesh, degree)\n",
    "    result_file = os.path.join(RESULT_DIR,\n",
    "                               f'{mesh}_{degree}.csv')\n",
    "    if not os.path.exists(result_file):\n",
    "        print(' not found, skipping')\n",
    "        continue\n",
    "\n",
    "    labels.append(f'{mesh} {degree}')\n",
    "\n",
    "    DF = pd.read_csv(result_file)\n",
    "    CORR = np.full((N, N), np.nan)\n",
    "    \n",
    "    for row in DF.itertuples():\n",
    "        CORR[row.SRC, row.DST] = row.CORR\n",
    "        \n",
    "    corrections.append(CORR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_POTENTIAL = np.full((N, N), np.nan)\n",
    "\n",
    "for src, SRC in POINTS.iterrows():\n",
    "    _src = common.PointSource(SRC.X,\n",
    "                              SRC.Y,\n",
    "                              SRC.Z,\n",
    "                              conductivity=BRAIN_CONDUCTIVITY)\n",
    "    for dst, DST in POINTS.iterrows():\n",
    "        BASE_POTENTIAL[src, dst] = _src.potential(DST.X, DST.Y, DST.Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OFF_DIAGONAL_IDX = ~np.eye(N, dtype=bool)\n",
    "\n",
    "print('Maximal reciprocity error:', abs(BASE_POTENTIAL - BASE_POTENTIAL.T)[OFF_DIAGONAL_IDX].max())\n",
    "_OFF_DIAGONAL = BASE_POTENTIAL[OFF_DIAGONAL_IDX]\n",
    "print('Linf:', abs(_OFF_DIAGONAL).max())\n",
    "print('L2:', np.sqrt(np.square(_OFF_DIAGONAL).mean()))\n",
    "print('L1:', abs(_OFF_DIAGONAL).mean())\n",
    "print('Median absolute value:', np.median(abs(_OFF_DIAGONAL)))\n",
    "print('min, med, max:', _OFF_DIAGONAL.min(), np.median(_OFF_DIAGONAL), _OFF_DIAGONAL.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exact solution approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We approximate exact solution as average of the most advanced FEM configurations\n",
    "# (in terms of mesh density and element degree)\n",
    "\n",
    "_corrections = dict(zip(labels, corrections))\n",
    "\n",
    "# AVG = 0.5 * (_corrections['finest 3'] + _corrections['finest 2'])\n",
    "AVG = _corrections['finest 3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Maximal reciprocity error:', abs(AVG - AVG.T)[OFF_DIAGONAL_IDX].max())\n",
    "_OFF_DIAGONAL = AVG[OFF_DIAGONAL_IDX]\n",
    "print('Linf:', abs(_OFF_DIAGONAL).max())\n",
    "print('L2:', np.sqrt(np.square(_OFF_DIAGONAL).mean()))\n",
    "print('L1:', abs(_OFF_DIAGONAL).mean())\n",
    "print('Median absolute value:', np.median(abs(_OFF_DIAGONAL)))\n",
    "print('min, med, max:', _OFF_DIAGONAL.min(), np.median(_OFF_DIAGONAL), _OFF_DIAGONAL.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reciprocity validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reciprocity_errors = [A - A.T for A in corrections]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reciprocity_relative_errors = [(A / (AVG + BASE_POTENTIAL))[OFF_DIAGONAL_IDX] for A in reciprocity_errors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.title('Reciprocity errors [V]')\n",
    "plt.yscale('symlog')\n",
    "plt.grid()\n",
    "\n",
    "_ = plt.boxplot([np.ravel(A) for A in reciprocity_errors],\n",
    "                labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.title('Modulus of reciprocity errors [V]')\n",
    "plt.yscale('log')\n",
    "plt.yticks(np.logspace(-8, 2, 11))\n",
    "plt.grid()\n",
    "_ = plt.violinplot([A[A > 0] for A in reciprocity_errors])\n",
    "_ = plt.boxplot([A[A > 0] for A in reciprocity_errors],\n",
    "                labels=labels)\n",
    "# _ = plt.violinplot([A[A > 0] for A in reciprocity_errors])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.title('Modulus of reciprocity errors [%]')\n",
    "plt.yscale('log')\n",
    "plt.yticks(np.logspace(-8, 2, 11))\n",
    "plt.grid()\n",
    "_ = plt.violinplot([A[A > 0] * 100 for A in reciprocity_relative_errors])\n",
    "_ = plt.boxplot([A[A > 0] * 100 for A in reciprocity_relative_errors],\n",
    "                labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convergence validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _corrections = dict(zip(labels, corrections))\n",
    "\n",
    "# removed = []\n",
    "# removal_score = []\n",
    "\n",
    "# _score = 1\n",
    "# while len(_corrections) > 2 and _score:\n",
    "#     _AVG = sum(_corrections.values()) / len(_corrections)\n",
    "#     _score = 0\n",
    "#     for _k, _CORR in _corrections.items():\n",
    "#         _s = np.sqrt(np.square(_AVG - _CORR).mean())\n",
    "#         if _s > _score:\n",
    "#             _score = _s\n",
    "#             _key = _k\n",
    "            \n",
    "#     removed.append(_key)\n",
    "#     removal_score.append(_score)\n",
    "#     del _corrections[_key]\n",
    "\n",
    "# AVG = sum(_corrections.values()) / len(_corrections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k, v in zip(removed, removal_score):\n",
    "#     print(f'  {k}\\t{v}')\n",
    "    \n",
    "# for k, v in zip(labels, corrections):\n",
    "#     if k in removed:\n",
    "#         continue\n",
    "    \n",
    "#     minimal_score = np.sqrt(np.square(v - AVG).mean())\n",
    "#     print(f'> {k}\\t{minimal_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(removal_score)\n",
    "# plt.axhline(minimal_score)\n",
    "# plt.yscale('log')\n",
    "# plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = [_CORR - AVG for _CORR in corrections]\n",
    "error_L1 = np.array([abs(_DIFF).mean() for _DIFF in diffs])\n",
    "error_L2 = np.array([np.sqrt(np.square(_DIFF).mean()) for _DIFF in diffs])\n",
    "error_Linf = np.array([abs(_DIFF).max() for _DIFF in diffs])\n",
    "error_bias = np.array([_DIFF.mean() for _DIFF in diffs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs_relative = [_DIFF / (AVG + BASE_POTENTIAL) for _DIFF in diffs]\n",
    "error_relative_L1 = np.array([abs(_DIFF[OFF_DIAGONAL_IDX]).mean() for _DIFF in diffs_relative])\n",
    "error_relative_L2 = np.array([np.sqrt(np.square(_DIFF[OFF_DIAGONAL_IDX]).mean()) for _DIFF in diffs_relative])\n",
    "error_relative_Linf = np.array([abs(_DIFF[OFF_DIAGONAL_IDX]).max() for _DIFF in diffs_relative])\n",
    "error_relative_bias = np.array([_DIFF[OFF_DIAGONAL_IDX].mean() for _DIFF in diffs_relative])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.title('Convergence errors [V]')\n",
    "plt.yscale('log')\n",
    "plt.grid()\n",
    "_ = plt.boxplot([abs(np.ravel(A)) for A in diffs],\n",
    "                labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.title('Convergence errors (diagonal excluded) [V]')\n",
    "plt.yscale('log')\n",
    "plt.grid()\n",
    "_ = plt.boxplot([abs(A[OFF_DIAGONAL_IDX]) for A in diffs],\n",
    "                labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.title('Convergence errors [%]')\n",
    "plt.yscale('log')\n",
    "plt.grid()\n",
    "_ = plt.boxplot([100 * abs(np.ravel(A)) for A in diffs_relative],\n",
    "                labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.title('Convergence errors (diagonal excluded) [%]')\n",
    "plt.yscale('log')\n",
    "plt.grid()\n",
    "_ = plt.boxplot([100 * abs(A[OFF_DIAGONAL_IDX]) for A in diffs_relative],\n",
    "                labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.title('Convergence errors [V]')\n",
    "\n",
    "plt.plot(error_L1, label='L1', marker='o')\n",
    "plt.plot(error_L2, label='L2', marker='+')\n",
    "plt.plot(error_Linf, label='L\\u221e')\n",
    "plt.plot(error_bias, label='bias')\n",
    "plt.yscale('symlog', linthresh=0.1)\n",
    "plt.xticks(range(len(labels)), labels)\n",
    "plt.grid()\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.title('Convergence errors [%]')\n",
    "\n",
    "plt.plot(100 * error_relative_L1, label='L1', marker='o')\n",
    "plt.plot(100 * error_relative_L2, label='L2', marker='+')\n",
    "plt.plot(100 * error_relative_Linf, label='L\\u221e')\n",
    "plt.plot(100 * error_relative_bias, label='bias')\n",
    "plt.yscale('symlog', linthresh=0.1)\n",
    "plt.xticks(range(len(labels)), labels)\n",
    "plt.grid()\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kesi3.7]",
   "language": "python",
   "name": "conda-env-kesi3.7-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
